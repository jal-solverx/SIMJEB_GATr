nohup: ignoring input
/home/ubuntu/miniforge3/envs/JHL_env/lib/python3.11/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/ubuntu/miniforge3/envs/JHL_env/lib/python3.11/site-packages/libpyg.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE
  warnings.warn(f"An issue occurred while importing 'pyg-lib'. "
/home/ubuntu/miniforge3/envs/JHL_env/lib/python3.11/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/ubuntu/miniforge3/envs/JHL_env/lib/python3.11/site-packages/libpyg.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE
  warnings.warn(f"An issue occurred while importing 'torch-sparse'. "
[train] sample_idx: 21 | shape of input: torch.Size([36544, 9]) | shape of bc: torch.Size([36544, 1])
[train] sample_idx: 30 | shape of input: torch.Size([21906, 9]) | shape of bc: torch.Size([21906, 1])
[train] sample_idx: 38 | shape of input: torch.Size([58270, 9]) | shape of bc: torch.Size([58270, 1])
[train] sample_idx: 62 | shape of input: torch.Size([28832, 9]) | shape of bc: torch.Size([28832, 1])
[train] sample_idx:  8 | shape of input: torch.Size([60068, 9]) | shape of bc: torch.Size([60068, 1])
[train] sample_idx:  9 | shape of input: torch.Size([97030, 9]) | shape of bc: torch.Size([97030, 1])
[train] sample_idx: 15 | shape of input: torch.Size([46732, 9]) | shape of bc: torch.Size([46732, 1])
[train] sample_idx: 23 | shape of input: torch.Size([43350, 9]) | shape of bc: torch.Size([43350, 1])
[train] sample_idx:  6 | shape of input: torch.Size([68746, 9]) | shape of bc: torch.Size([68746, 1])
[train] sample_idx: 10 | shape of input: torch.Size([86471, 9]) | shape of bc: torch.Size([86471, 1])
[train] sample_idx: 22 | shape of input: torch.Size([75949, 9]) | shape of bc: torch.Size([75949, 1])
[train] sample_idx: 63 | shape of input: torch.Size([53387, 9]) | shape of bc: torch.Size([53387, 1])
[train] sample_idx: 14 | shape of input: torch.Size([95091, 9]) | shape of bc: torch.Size([95091, 1])
[train] sample_idx: 29 | shape of input: torch.Size([231760, 9]) | shape of bc: torch.Size([231760, 1])
[train] sample_idx: 35 | shape of input: torch.Size([65106, 9]) | shape of bc: torch.Size([65106, 1])
[train] sample_idx: 40 | shape of input: torch.Size([28666, 9]) | shape of bc: torch.Size([28666, 1])
[train] sample_idx: 19 | shape of input: torch.Size([90058, 9]) | shape of bc: torch.Size([90058, 1])
[train] sample_idx: 27 | shape of input: torch.Size([63483, 9]) | shape of bc: torch.Size([63483, 1])
[train] sample_idx: 28 | shape of input: torch.Size([59952, 9]) | shape of bc: torch.Size([59952, 1])
[train] sample_idx: 33 | shape of input: torch.Size([167845, 9]) | shape of bc: torch.Size([167845, 1])
[valid] sample_idx: 20 | shape of input: torch.Size([57168, 9]) | shape of bc: torch.Size([57168, 1])
[valid] sample_idx:  4 | shape of input: torch.Size([87908, 9]) | shape of bc: torch.Size([87908, 1])
[valid] sample_idx:  0 | shape of input: torch.Size([112873, 9]) | shape of bc: torch.Size([112873, 1])
[valid] sample_idx: 12 | shape of input: torch.Size([123939, 9]) | shape of bc: torch.Size([123939, 1])
[valid] sample_idx: 16 | shape of input: torch.Size([62273, 9]) | shape of bc: torch.Size([62273, 1])
# of train dataset: 20
# of valid dataset 5
experiment:
  seed: 36
  device: cuda:3
  wandb: true
  wandb_api_key: 899079d77b6e3f0774afe79065ae85b86ac909d2
  wandb_project_name: vanilla_gotennet
dataset:
  data_dir: /data/SimJEB/
  max_epochs: 300
  train_sample_id:
  - 21
  - 30
  - 38
  - 62
  - 8
  - 9
  - 15
  - 23
  - 6
  - 10
  - 22
  - 63
  - 14
  - 29
  - 35
  - 40
  - 19
  - 27
  - 28
  - 33
  valid_sample_id:
  - 20
  - 4
  - 0
  - 12
  - 16
arch:
  processor:
    hidden_dim: 64
    n_layers_GATA: 4
    n_rbf: 32
    max_z: 4
    n_attn_heads: 8
    max_angular_momentum: 2
    aggregation_func: add
    edge_refinement_dim: 256
scheduler:
  initial_lr: 0.0002
  lr_decay: 0.8
  lr_patience: 30
  gradient_clipping: 10
  weight_decay: 0.01
  dropout_rate: 0.1

=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
GotenNetWrapper                          --
├─CosineCutoff: 1-1                      --
├─NodeInit: 1-2                          --
│    └─SumAggregation: 2-1               --
│    └─Embedding: 2-2                    256
│    └─MLP: 2-3                          --
│    │    └─ModuleList: 3-1              2,112
│    │    └─Sequential: 3-2              2,112
│    └─MLP: 2-4                          --
│    │    └─ModuleList: 3-3              12,544
│    │    └─Sequential: 3-4              12,544
│    └─CosineCutoff: 2-5                 --
├─EdgeInit: 1-3                          --
│    └─Linear: 2-6                       2,112
├─ExpNormalSmearing: 1-4                 --
│    └─CosineCutoff: 2-7                 --
├─Embedding: 1-5                         256
├─TensorInit: 1-6                        --
├─ModuleList: 1-7                        --
│    └─GATA: 2-8                         --
│    │    └─SumAggregation: 3-5          --
│    │    └─Sequential: 3-6              16,640
│    │    └─Dense: 3-7                   4,160
│    │    └─Dense: 3-8                   4,160
│    │    └─Sequential: 3-9              16,640
│    │    └─Dense: 3-10                  4,160
│    │    └─MLP: 3-11                    4,160
│    │    └─Dense: 3-12                  16,384
│    │    └─ModuleList: 3-13             32,768
│    │    └─Dense: 3-14                  16,448
│    │    └─Sequential: 3-15             16,448
│    │    └─CosineCutoff: 3-16           --
│    │    └─Dense: 3-17                  12,480
│    │    └─Identity: 3-18               --
│    │    └─Identity: 3-19               --
│    └─GATA: 2-9                         --
│    │    └─SumAggregation: 3-20         --
│    │    └─Sequential: 3-21             16,640
│    │    └─Dense: 3-22                  4,160
│    │    └─Dense: 3-23                  4,160
│    │    └─Sequential: 3-24             16,640
│    │    └─Dense: 3-25                  4,160
│    │    └─MLP: 3-26                    4,160
│    │    └─Dense: 3-27                  16,384
│    │    └─ModuleList: 3-28             32,768
│    │    └─Dense: 3-29                  16,448
│    │    └─Sequential: 3-30             16,448
│    │    └─CosineCutoff: 3-31           --
│    │    └─Dense: 3-32                  12,480
│    │    └─Identity: 3-33               --
│    │    └─Identity: 3-34               --
│    └─GATA: 2-10                        --
│    │    └─SumAggregation: 3-35         --
│    │    └─Sequential: 3-36             16,640
│    │    └─Dense: 3-37                  4,160
│    │    └─Dense: 3-38                  4,160
│    │    └─Sequential: 3-39             16,640
│    │    └─Dense: 3-40                  4,160
│    │    └─MLP: 3-41                    4,160
│    │    └─Dense: 3-42                  16,384
│    │    └─ModuleList: 3-43             32,768
│    │    └─Dense: 3-44                  16,448
│    │    └─Sequential: 3-45             16,448
│    │    └─CosineCutoff: 3-46           --
│    │    └─Dense: 3-47                  12,480
│    │    └─Identity: 3-48               --
│    │    └─Identity: 3-49               --
│    └─GATA: 2-11                        --
│    │    └─SumAggregation: 3-50         --
│    │    └─Sequential: 3-51             16,640
│    │    └─Dense: 3-52                  4,160
│    │    └─Dense: 3-53                  4,160
│    │    └─Sequential: 3-54             16,640
│    │    └─Dense: 3-55                  4,160
│    │    └─CosineCutoff: 3-56           --
│    │    └─Dense: 3-57                  12,480
│    │    └─Identity: 3-58               --
│    │    └─Identity: 3-59               --
├─ModuleList: 1-8                        --
│    └─EQFF: 2-12                        --
│    │    └─Sequential: 3-60             16,576
│    │    └─Dense: 3-61                  4,096
│    └─EQFF: 2-13                        --
│    │    └─Sequential: 3-62             16,576
│    │    └─Dense: 3-63                  4,096
│    └─EQFF: 2-14                        --
│    │    └─Sequential: 3-64             16,576
│    │    └─Dense: 3-65                  4,096
│    └─EQFF: 2-15                        --
│    │    └─Sequential: 3-66             16,576
│    │    └─Dense: 3-67                  4,096
├─Distance: 1-9                          --
=================================================================
Total params: 618,688
Trainable params: 618,688
Non-trainable params: 0
=================================================================
Traceback (most recent call last):
  File "/data/temp_Jongann/SimJEB_GATr/vanilla_GotenNet/train_goten.py", line 34, in <module>
    trainer.train(cfg)
  File "/data/temp_Jongann/SimJEB_GATr/vanilla_GotenNet/train.py", line 233, in train
    pred, _ = self.model(graph)
              ^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniforge3/envs/JHL_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniforge3/envs/JHL_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/temp_Jongann/SimJEB_GATr/vanilla_GotenNet/gotennet/models/representation/gotennet.py", line 949, in forward
    h, X = super().forward(atomic_numbers, edge_index, edge_diff, edge_vec)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/temp_Jongann/SimJEB_GATr/vanilla_GotenNet/gotennet/models/representation/gotennet.py", line 902, in forward
    h, X, t_ij = gata(edge_index, h, X, rl_ij=rl_ij, t_ij=t_ij, r_ij=edge_diff, n_edges=n_edges) # idx_i, idx_j, n_atoms, # , f_ij=f_ij
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniforge3/envs/JHL_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniforge3/envs/JHL_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/temp_Jongann/SimJEB_GATr/vanilla_GotenNet/gotennet/models/representation/gotennet.py", line 420, in forward
    dt_ij = self.edge_updater(edge_index, EQ=EQ, EK=EK, rl_ij=rl_ij, t_ij=t_ij)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/tmp/gotennet.models.representation.gotennet_GATA_edge_updater_l2z7byb6.py", line 169, in edge_updater
    out = self.edge_update(
          ^^^^^^^^^^^^^^^^^
  File "/data/temp_Jongann/SimJEB_GATr/vanilla_GotenNet/gotennet/models/representation/gotennet.py", line 560, in edge_update
    EQ_i_l = self.vector_rejection(EQ_i_split[l], rl_ij_split[l])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/temp_Jongann/SimJEB_GATr/vanilla_GotenNet/gotennet/models/representation/gotennet.py", line 342, in vector_rejection
    return rep - vec_proj * rl_ij.unsqueeze(2)
           ~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.58 GiB. GPU 3 has a total capacity of 79.15 GiB of which 1.63 GiB is free. Including non-PyTorch memory, this process has 69.51 GiB memory in use. Process 773681 has 8.00 GiB memory in use. Of the allocated memory 67.81 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
